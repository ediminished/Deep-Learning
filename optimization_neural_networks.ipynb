{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "insured-fever",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-compensation",
   "metadata": {},
   "source": [
    "# Universal Approximation Theorem:\n",
    "* ### It states that we will be able to approximate any kind of function with neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-standard",
   "metadata": {},
   "source": [
    "Gradient descent update rule:\n",
    "w = w - n(derivative of loss function wrt w)\n",
    "... wherer n: learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-order",
   "metadata": {},
   "source": [
    "Can we come up with a better update rule?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-chain",
   "metadata": {},
   "source": [
    "# Vanilla Gradient Descent limitation:\n",
    "* ### In plateu/ low-slope/ flatter regions, the algorithm doesn't move fast enough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-student",
   "metadata": {},
   "source": [
    "# Momentum based Gradient Descent Algorithm:\n",
    "*  Here, we take an Exponentially Decaying Weighted Sum, whereby as we move further and further into the series, the weight decays more.\n",
    "*  The intuition behind this is as we progress further and further down a series/direction, we can place lesser and lesser importance to the later gradients as we move along the same direction\n",
    "*  Advantage:\n",
    "    1. Even in the regions with the gentle slopes, momentum based gradient descent is able to take large steps because of weighted avg sum\n",
    "*  Disadvantage:\n",
    "    1. There could be a situation where momentum could cause us to overshoot our goal (minima) which will cause oscillations in the valley\n",
    "    2. Can we improve this a little bit so that we take larger steps with gentle slope region but reduce the number of oscillations at the time of convergence ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-estimate",
   "metadata": {},
   "source": [
    "# Nesterov Accelerated GD: (NAG)\n",
    "* We can consider first moving with the history term, then calculate the second step from where we were located after the first step\n",
    "* Advantages\n",
    "    1. Quicker than momentum based gradient descent\n",
    "    2. Oscillations are smaller and chances of escaping from minima valley are smaller than Momentum based GD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-setting",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent\n",
    "* Consider a training set with 1 million data points\n",
    "* With Gradient Descent, we calculate the derivatives for each of these points\n",
    "* Once weâ€™re done, we update the parameters\n",
    "* Thus, we pass over all 1 million points to make a single update to w & b\n",
    "* It can also be called batch gradient descent, as the entire dataset is used as a single batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-symposium",
   "metadata": {},
   "source": [
    "# Mini-batch Gradient Descent \n",
    "* However, we can choose to make an approximation based on looking at a smaller portion(batch) of the data points instead of analysing the whole dataset each time.\n",
    "* This is called mini-batch gradient descent\n",
    "* Consider a training set of 1 million data points\n",
    "* Select a batch size of 100 data points\n",
    "* What this means is that every batch, the algorithm calculates all of the 100 derivatives and updates the parameters\n",
    "* Thus, passing over all 1 million data points results in 10000 updates to w & b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-intro",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "* Stochastic gradient descent is when the batch size is 1, i.e. an update to the parameters after each single data point\n",
    "* One key thing to note is that both stochastic and mini-batch gradient descent are approximations of the true derivative obtained by batch gradient descent.\n",
    "* However it is advantageous as it allows is to make updates faster and achieve quicker progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-version",
   "metadata": {},
   "source": [
    "# Epochs and Steps\n",
    "* 1 epoch = one pass over the entire data\n",
    "* 1 step = one update of th parameters\n",
    "* N = Number of data points\n",
    "* B = Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-sender",
   "metadata": {},
   "source": [
    "| Algorithm | # of steps in  one epoch |\n",
    "| :--- |:---\n",
    "| Batch gradient descent | 1\n",
    "| Stochastic gradient descent | N\n",
    "| Mini-batch gradient descent | N/B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-uncertainty",
   "metadata": {},
   "source": [
    "# Adapative learning rate: \n",
    "* For sparse features, we should have larger learning rate\n",
    "* For dense features, we should have smaller learning rate\n",
    "* So the question is, can we have different learning rate for each parameter which takes care of frequency of features ??\n",
    "* Intuition: Decay the learning rate for parameters in proportion to their update history. (Fewer updates, lesser decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-nicholas",
   "metadata": {},
   "source": [
    "# Adagrad\n",
    "* Parameter corresponding to sparse features get better updates\n",
    "* Limitation:\n",
    "   * The effective learning rate corresponding to desnse features is decaying aggresively as the denominator grows \n",
    "   * So here the intuition behind the solution of this limitation is, why not decay the denominator and prevent the rapid growth?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-oxford",
   "metadata": {},
   "source": [
    "# RMSProp\n",
    "* Adagrad stuck when it was closer to convergence\n",
    "* RMSProp overcomes this problem by becoming less aggressive on the decay\n",
    "    * Can I do better than this? Am I asking for too much? \n",
    "    * Wait, can we get best of both the worlds?\n",
    "    * Can we combine the history terms of Momentum based GD and RMSProp together? This is what Adam does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-requirement",
   "metadata": {},
   "source": [
    "# Adam\n",
    "* Momentum based GD: Makes use of history of the gradients\n",
    "    * i.e. History is used to calculate current update\n",
    "* RMSProp: Makes use of history of the square of the gradients\n",
    "    * i.e. History is used to adjust the learning rate\n",
    "* Adam combines both these algorithms together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-integration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-tower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "certified-egypt",
   "metadata": {},
   "source": [
    "# What happens if there are no non-linear activation functions in the network? \n",
    "* $\\hat y _{i} = W_{3}(W_{2}(W_{1}x_{i}))$  i.e. Just the linear transformation\n",
    "    * i.e. Can only represent linear relations between x and y\n",
    "    * UAT does not hold !!\n",
    "    * The representation power of a deep NN is due to its non-linear activation functions !!\n",
    "    * This is like ,\"Aapne to humse hamara guroor hi chhin liya\"\n",
    "    * So the whole neural network can do nothing without non-linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-plane",
   "metadata": {},
   "source": [
    "# Logistic function (a.k.a. Sigmoid) \n",
    " <img src=\"./optimization_algorithms/img/sigmoid.png\" width=800 height=800 style=\"background-color:white;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-iraqi",
   "metadata": {},
   "source": [
    "* $f(x)= \\frac{1}{1+e^{-x}}$\n",
    "* $f(x) = f(x)*(1-f(x))$\n",
    "* Saturation: When f(x) = 0 or 1\n",
    "* and hence $ f^{'}(x) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-phenomenon",
   "metadata": {},
   "source": [
    "### This means, if there is a saturated neuron associated with the chain, then the entire gradient becomes 0  \n",
    "* Due to this, weights will not get updated\n",
    "* This is called Vanishing Gradient  Problem, because the gradient vanishes or reduces to 0 due to presence of saturated neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-extension",
   "metadata": {},
   "source": [
    "### Limitations of sigmoid\n",
    "* Sigmoid function is not zero centered\n",
    "* Causes vanishing gradient problem\n",
    "* Computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-template",
   "metadata": {},
   "source": [
    "# Tanh function \n",
    " <img src=\"./optimization_algorithms/img/tanh.png\" width=800 height=800 style=\"background-color:white;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-relay",
   "metadata": {},
   "source": [
    "* $f(x)= \\frac{e^{x} - e^{-x}}{e^{x}+e^{-x}}$\n",
    "* $f^{'}(x) = (1-f(x)^{2})$\n",
    "* Saturation: When f(x) = 0 or 1\n",
    "* and hence $ f^{'}(x) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-cathedral",
   "metadata": {},
   "source": [
    "* ### Still tanh neurons cause the gradients to vanish\n",
    "* ### tanh is zero centered\n",
    "* ### tamh is computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-poland",
   "metadata": {},
   "source": [
    "# ReLU function  \n",
    " <img src=\"./optimization_algorithms/img/relu.png\" width=500 height=800 style=\"background-color:white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-cruise",
   "metadata": {},
   "source": [
    "* $f(x)= max(0,x)$\n",
    "* $f^{'}(x) = 0 , {} if x < 0 $\n",
    "* $f^{'}(x) = 1 if x >  0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-belgium",
   "metadata": {},
   "source": [
    "* #### Does not saturate in the positive region\n",
    "* #### Not zero centered\n",
    "* #### Easy to compute\n",
    "* #### A large fraction of ReLU units can die if the learning rate is set too high\n",
    "* #### It is advised to initialize bias to a positive value\n",
    "* #### Use another version of ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-acquisition",
   "metadata": {},
   "source": [
    "# Leaky ReLU   \n",
    " <img src=\"./optimization_algorithms/img/leaky_relu.ppm\" width=500 height=800 style=\"background-color:white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-spice",
   "metadata": {},
   "source": [
    "* $f(x)= max(0.01,x)$\n",
    "* $f^{'}(x) = 0.01 :  if : x < 0 $\n",
    "* $f^{'}(x) = 1  :if: x >  0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-grammar",
   "metadata": {},
   "source": [
    "* #### Does not saturate in positive or negative region\n",
    "* #### Will not die (0.01 x ensures that at least a small gradient will flow through)\n",
    "* #### Easy to compute \n",
    "* #### Close to zero-centered outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-emphasis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-money",
   "metadata": {},
   "source": [
    "# Initialization methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-preference",
   "metadata": {},
   "source": [
    "* #### Never initialize all weights equal to 0\n",
    "* #### Never initialize all weights to same value because this will create symmetry breaking problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-startup",
   "metadata": {},
   "source": [
    "* #### Always normalize the inputs (so that they lie between 0 and 1)\n",
    "* #### Never initialize weights to larger values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-endorsement",
   "metadata": {},
   "source": [
    "## Xavier Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-apparatus",
   "metadata": {},
   "source": [
    "* To avoid saturation due to extremely large value, weights should scale inversely with the number of input neurons\n",
    "* $ w \\: \\alpha \\: \\frac{1}{\\sqrt {n}}$ \n",
    "* Used in case of tanh and logistic function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-degree",
   "metadata": {},
   "source": [
    "## He Initialization\n",
    "* $ w \\: \\alpha \\: \\frac{1}{\\sqrt {n/2}}$ \n",
    "* Here we divide n by 2 because of the rough intuition that in ReLU, around half the neurons die during training\n",
    "* Use He initialization for ReLU and Leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-flooring",
   "metadata": {},
   "source": [
    "| Activation function | When to use |\n",
    "| :--- |:---\n",
    "| sigmoid | Don't use\n",
    "| tanh | RNN\n",
    "| relu | CNNs\n",
    "| leaky Relu | CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-joshua",
   "metadata": {},
   "source": [
    "| Initialization method | When to use |\n",
    "| :--- |:---\n",
    "| Zero, equal, large | Never use\n",
    "| Xavier | tanh, sigmoid \n",
    "| He | relu, leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-caution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-march",
   "metadata": {},
   "source": [
    "## L2 Regularization\n",
    "* Let $\\theta$ be our parameters\n",
    "* Out aim is to minimize the loss function i.e. $ min _{\\theta} L(\\theta) $ .. but wait, there are some other quantities too\n",
    "* Let $ \\Omega(\\theta)$ be some other quantities that are dependent on our parameters\n",
    "* $ \\Omega(\\theta) = ||\\theta||^{2} _{2} \\: \\: \\:$  i.e. square root of sum of squares of weights\n",
    "* In order to prevent the other quantities from driving high, we need to minimize them too. i.e. we need to minimize the loss function\n",
    "* But, at the same time, we should not allow the weights to grow too large\n",
    "* Thus, in L2 regularization, we do not allow the training loss to be brought to be zero; \n",
    "* Instead we maintain it slightly below zero so that $\\Omega$  doesn't become too high\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-belly",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "* Augmenting with more data will make tougher training to the model\n",
    "* But we might end up seeing data which is similar to valid/test data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-appliance",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "* As we train more and more, the training error decreases but validation error increases\n",
    "* So we apply early stopping to prevent that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-daisy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-supply",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "welcome-stick",
   "metadata": {},
   "source": [
    "* Deep Neural Networks are highly complex models,(many parameters, many non-linearities)\n",
    "* Easy to overfit (training error drives easily to 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-brick",
   "metadata": {},
   "source": [
    "* Divide data into train, validation and test splits\n",
    "* Make sure you are using \n",
    "    * Right activation function\n",
    "    * Right initialization method\n",
    "    * Right optimization method\n",
    " * Monitor training and validation error (do not touch the test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-morocco",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "* Network architectures\n",
    "    * Number of layers\n",
    "    * Number of neurons\n",
    "    \n",
    "* Algorithm\n",
    "    * Vanilla Gradient Descent\n",
    "    * AdaGrad\n",
    "    * RMS Prop\n",
    "    * Adam\n",
    "    \n",
    "* Strategies\n",
    "    * Batch \n",
    "    * Mini-batch (32, 64, 128)\n",
    "    * Stochastic\n",
    "    * Learning rate schedule\n",
    "\n",
    "* Activation function\n",
    "    * tanh (RNN)\n",
    "    * ReLU (CNNs, DNNs)\n",
    "    * Leaky ReLU (CNNs)\n",
    "    \n",
    "* Initialization \n",
    "    * Xavier\n",
    "    * He\n",
    "    \n",
    "* Regularization\n",
    "    * L2\n",
    "    * Early stopping\n",
    "    * Dataset augmentation\n",
    "    * Drop-out\n",
    "    * Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-grace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
